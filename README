Notes on lesgo by:
      Stuart Chester
      Jason Graham

//////////////////////////////////////////////////////////////////////
/// DISCLAIMER                                                     ///
//////////////////////////////////////////////////////////////////////

Please keep in mind that many parts of the code were developed without a
clear idea of exactly where the program was headed, since various ideas
are tried and discarded as part of the research process.  This means
that code organization is not optimal in some spots, and that not all
options are fully implemented.  My advice is ALWAYS read whatever parts
of the code you are using to find out what they really do.

//////////////////////////////////////////////////////////////////////
/// OVERVIEW                                                       ///
//////////////////////////////////////////////////////////////////////

The code can simulate turbulent flow over tree geometries and is divided
into several major parts:

1) LES flow solver

2) Level set immersed boundary implementation (level_set*.f90).

3) Renormalized numerical simulation (subgrid force modeling; depends
   on IB implementation)

4) Wind farm modeling 

5) Concurrent precursor simulation

Each part will be discussed in their respective sections.

//////////////////////////////////////////////////////////////////////
/// DEPENDENCIES                                                   ///
//////////////////////////////////////////////////////////////////////

The following dependencies are required in order to compile lesgo:

* Fortran 95 compiler: 

  Most modern compilers will work fine. Ones that have been used
  successfully are G95, GFortran (>= 4.4), Intel, and PGI

* makedepf90 (http://www.helsinki.fi/~eedelman/makedepf90.html) 

  The Makefile makes use of this to determine file dependencies.

* fpx3 (http://wwwuser.gwdg.de/~jbehren/fpx3)

  This is a fortran preprocessor. The main reason this is used is to
  isolate calls to MPI libraries, so that if someone wants to run the
  code in non-MPI mode, then it will compile cleanly and the
  compiler/linker will not complain about missing MPI libraries. fpx3
  macros are also used to hide some other definitions from the compiler,
  e.g., some array dimensions. The Makefile runs the preprocessor as a
  step in compilation.

* tecryte (http://panoramix.me.jhu.edu/~jgraham/codes/tecryte/)

  Currently all of the data output is written in Tecplot format. tecryte
  is a library that we have developed to write data to Tecplot formatted
  files. All of the data is written in block format and has been
  optimized to work well over both local and distributed file systems.


//////////////////////////////////////////////////////////////////////
/// LES FLOW SOLVER                                                ///
//////////////////////////////////////////////////////////////////////

The LES flow solver is parallelized with MPI. The key here is the
pressure solver. I chose to use a pipelining technique to parallelize
this, since it is simple and there isn't really any better options for
parallelizing the solution of many small tridiagonal systems.  The best
size of the chunks to send "down the pipeline" can be controlled via the
variable "chunksize", and WILL depend on the computer hardware and
simulation size.  It would probably advantageous to add a routine that
adjusts the chunk size automatically by making speed measurements at the
beginning of the simulation.

The flow domain is evenly divided in the vertical (z) direction between
the MPI processes.  Each MPI-process has its "own" z-levels indexed by
jz = 1 to nz-1.  The z-levels jz = 0 and jz = nz are only for holding
data that has been copied from the process below or above the current
one.

The immersed boundary forces are used by the trees and level set code,
so if something is changed here, then check dependent parts of the code
in those modules.


//////////////////////////////////////////////////////////////////////
/// LEVEL SET IMMERSED BOUNDARY METHOD                             ///
//////////////////////////////////////////////////////////////////////

To use the level set modules in a simulation, a file "phi.out"
containing the signed distance function data must be created first.
This must be generated with a separate program, see the program in
"trees_pre_ls.f90" for making the tree level set files.  I recommend
making the signed distance function exact if possible, or at least
sampled at a higher resolution than the computational grid.  There are
many adjustable parameters within level_set.f90 that control how the
boundary conditions at the level set surface are applied.  If you
encounter problems (e.g., kinks in velocity profiles), try adjusting
some of these (e.g., length scale parameters that control how close a
given point must be to the surface before an certain action is taken).
Just make sure to read all code associated with some of these
parameters, since some are experimental, and may not be ready for "prime
time".

The variables "nphitop", "nphibot", etc., control how many extra
z-levels are copied between MPI processes when determining boundary
conditions (at top and bottom of the process-local domain).  The values
to use here are geometry dependent, and it is pretty hard to determine
in advance exactly what they should be. These values should be as small
as possible so the MPI transfers involve the least amount of data.
Right now, my approach has been to pick some initial values and when the
code fails, then increase the values.  the good news here is that all
the code using these is manually bounds-checked, so if an out-of-bounds
reference is made, the code should always die with an error message
saying which parameter is the problem and offer a suggestion as to what
a better value would be. Another weakness is that the number of extra
z-levels is the same for all processes, when for maximum efficiency,
they really should be allowed to differ.  It should be possible to have
the code auto-dimension the "nphitop", etc., for each process.  On the
other hand, this means that those processes that finish their boundary
conditions faster that the other processes will have to wait, so unless
they are given something useful to do, it is probably not worth the
effort.

 
//////////////////////////////////////////////////////////////////////
/// RENORMALIZED NUMERICAL SIMULATION                              ///
//////////////////////////////////////////////////////////////////////

TREES 

The trees modules rely heavily on the tree and branch data structures
(derived types) defined in "trees_base_ls.f90". These data structures
can handle non-fractal trees, but most of the routines that do the
actual work assume self similar fractal trees. Since a tree generally
consists of a trunk and generations of sub-branches, most routines in
"trees_ls.f90", etc., use recursive routines to visit each branch of the
tree data structure. This usually looks like this: a routine takes a
branch as input and does whatever operations it needs to on that branch
before calling itself, but now with each of the input branch's
child-branches as input. The value of "fmodel" in "trees_base_ls.f90"
sets the RNS force model used: d is for drag only, d_germano is for drag
only and the Germano formulation, dls stand for drag-lift-side forces,
and nba stands for normal-binormal-axial.

As with the level set modules, there are many options (some not all
fully supported), so read the code as much a possible to determine what
they do.

To do a simulation using the trees, the user has to write a "trees.conf"
file. An example is:

--------------begin trees.conf-----------
# This is a trees configuration file
# this is a comment, it begins with a #

n_tree = 1

# see trees_setup_ls.f90 to see what each of these parameters does
tree = {
  n_gen = 2
  n_sub_branch = 4
  l = 0.3125
  d = 0.125
  #x0 = 0.5, 0.5, 0.0078125
  x0 = 0.5, 0.5, 0.0
  taper = 0.
  ratio = 0.48
  rel_dir = -0.4924038763,-0.8528685321,-0.1736481773,
0.0000000000,0.0000000000,1.0000000000,
-0.4924038763,0.8528685320,-0.1736481773,
0.9848077530,0.0000000000,-0.1736481773
  root_height = 0.75, 1.0, 0.75, 0.75
  twist = -90.0, 0.0, -90.0, -90.0
  #trunk_twist = 90.0
  max_res_gen=1
}
--------------end trees.conf--------------

This creates a tree structure with 2 generations of branches (the trunk
counts as generation zero), with each branch having 4 sub-branches.  The
length of each the trunk is 0.3125 and the diameter of the trunk is
0.125.  If the add_cap option is true, then the actual length of the
tree trunk will be l + d/2 = 0.3125 + 0.125/2 = 0.375.  The center of
the base of the trunk is at x0 (given as x,y,z coordinates).  The
branches are not tapered.  The ratio of lengths between a branch and
each of its sub-branches is 0.48.  The directions of the sub-branches,
relative to the parent-branch coordinate system are sub-branch 1:
(-0.49, -0.85, -.17) sub-branch 2: (0, 0, 1) sub-branch 3: (-0.49, 0.85,
-0.17) sub-branch 4: (0.98, 0, -0.17) To see how the branch-local
coordinate systems are defined, see trees_setup_ls.f90. Three
sub-branches are placed 75 % of the way along the parent branch
(root_height), and one is at the top of the parent branch.  Each
sub-branch has a twist about its own branch axis applied to it.  The
trunk can be twisted separately, but this line has been commented out.
The maximum resolved generation(max_res_gen) used in RNS is generation
1, note that there n_gen = 2 is one more than the last resolved
generation.  The is mean that generation two are the unresolved RNS
branches.  Even if you want to simulate more that one unresolved branch
generation, right now the code expects max_res_gen + 1 = n_gen.  Note
that although the relations between a branch and its sub-branches are
defined in trees.conf, iterated function systems (IFS) ARE NOT USED to
describe the trees.  Instead, a sub-branch is defined only by reference
to its parent branch.

Next, use trees_pre_ls.f90 to read the trees.conf file and calculate the
level set function required by the level set routines, as well as the
branch index arrays (brindex.out).

After running trees_pre_ls.f90, you should be all set to begin an LES or RNS/LES
computation.

The trees modules are isolated from the LES core and level set modules
as much as possible, but some dependence was unavoidable, so always
check that these parts are "in sync".

SKEWED CYLINDERS TREES


//////////////////////////////////////////////////////////////////////
/// DATA OUTPUT                                                    ///
//////////////////////////////////////////////////////////////////////

The master switch for all data output in the code is in param.f90. The
switch for controlling this is called output. All parameters for
controlling what, when and how frequent data is computed or recorded is
in stats_init.f90. A brief description of what each setting does is
given below.

1) tavg_t - type for time averaged statistics

Settings:
a) calc - controls the output of the average velocity field for the entire
domain; Reynold stress calculations will force this flag to be true if required;
output file: uvw_avg.dat

b) nstart - iteration number of the current simulation which time averaging
starts

c) nend - iteration number of the current simulation which time averaging ends


2) rs_t - controls the calculation of Reynolds stress; depends on tavg_t

Settings:
a) calc - controls the output of Reynolds stresses for the entire domain; output
file: rs.dat


3) point_t - controls the recording of instantaneous velocity and a specified
point

Settings:
a) calc - turn on/off recordings; output file: uvw_inst-{xloc}-{yloc}-{zloc}.dat
(where xloc,yloc,zloc is specified by xyz)

b) nstart - iteration number of the current simulation which recording starts

c) nend   - iteration number of the current simulation which recording ends

d) nskip  - number of iterations to skip between recordings

e) nloc - number of points (or locations) to record (maximum 10)

f) xyz - x,y,z location of point to record; important - the first dimension
determines either x,y,or z and the second dimension is the location number (ex:
xyz(3,2) - z location of 2nd specified point)


4) domain_t - type for writing instantaneous velocity field of entire domain to
file

Settings:
a) calc - turn on/off recordings; output file: uvw.{iteration}.out; these files
are binary data and must be converted to Tecplot formatted files using
lesgo_post

b) nstart - iteration number of the current simulation which recording starts

c) nend   - iteration number of the current simulation which recording ends

d) nskip  - number of iterations to skip between recordings


5) plane_t - type used for recording y (yplane_t) and z (zplane_t) plane time
averaged velocity 

Settings: 
a) calc - turn on/off recordings; output file: uvw_avg.{y,z}-{loc}.dat (where
loc is the specified plane location)

b) nstart - iteration number of the current simulation which recording starts

c) nend   - iteration number of the current simulation which recording ends

d) nloc - number of planes (or locations) to record (maximum 10)

e) loc - plane value to record (ex: loc(1)=1.25)

NOTE: When running MPI jobs all the output files mentioned above that store
non-constant z valued information (so everything except for point_t and
zplane_t) will have appended to the afore mentioned file names the processor
number that created the file. The processor number used is coords in lesgo which
is arranged to be in the increasing z-direction.

Added work around for writing large 3D data: only write 3 variables
at a time; since things are written in block format this can be
done with mulitple calls to write_real_data_3D. General rule of
thumb keep the number of points passed to write_real_data_3D 
less than 1000000.

TREATMENT OF POINTS AND PERIODICITY

More to come ...
