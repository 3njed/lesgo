!**********************************************************************
module cuda_derivatives
!**********************************************************************
use cudafor
implicit none

type(dim3) :: dimGrid, dimBlock

contains

!**********************************************************************
subroutine cuda_derivatives_init()
!**********************************************************************
use param, only : lh, ny, batchsize, blx, bly, blz
implicit none

integer :: grid_x, grid_y, grid_z

grid_x = lh/blx + min(1,modulo(lh,blx))
grid_y = ny/bly + min(1,modulo(ny,bly))
!grid_z = batchsize/blz + min(1,modulo(batchsize,blz))
grid_z = 1

dimGrid = dim3( grid_x, grid_y, grid_z)
dimBlock = dim3( blx, bly, blz )
!dimGrid = dim3( grid_x, grid_y, 1)
!dimBlock = dim3( blx, bly, 1 )

end subroutine cuda_derivatives_init

!**********************************************************************
subroutine cuda_ddx( a, dadx, lbz )
!**********************************************************************
use types
use param, only : nx, ny, ld, lh, nz, batchsize, blx, bly
use cuda_fft

implicit none

integer :: jb,jstart,jend,jbatch, nbatch
integer, intent(in) :: lbz

real(rprec), dimension(:,:,lbz:), intent(in) :: a
real(rprec), dimension(:,:,lbz:), intent(inout) :: dadx
real(rprec), parameter :: const = 1._rprec / (nx*ny)

integer :: nb
real(rprec), device, allocatable, dimension(:,:,:) :: dadx_dev

allocate(dadx_dev(ld,ny,batchsize))

nbatch = (nz - lbz + 1) / batchsize

dadx = const*a

do jbatch=1, nbatch
 
  jstart = (jbatch-1)*batchsize + 1
  jend = jstart + batchsize - 1
 
  !  Copy data to device
  dadx_dev = dadx(:,:,jstart:jend)

  call cufftExecD2Z(cuda_forw,dadx_dev,dadx_dev)

  !  k should take care of the 0's
  !dadx(ld-1:ld,:,jz)=0._rprec 
  !dadx(:,ny/2+1,jz)=0._rprec
  do nb=1, batchsize
    !  Compute derivative
    call cuda_emul_cmplx_mult_inpl_rci_2D<<< dimGrid, dimBlock >>>(&
      dadx_dev(:,:,nb), kx_dev, ld, lh, ny )
  enddo
 
  call cufftExecZ2D(cuda_back,dadx_dev,dadx_dev)      

  !  Copy back to host
  dadx(:,:,jstart:jend) = dadx_dev

enddo

deallocate(dadx_dev)

return
end subroutine cuda_ddx

!**********************************************************************
attributes(global) subroutine cuda_emul_cmplx_mult_inpl_rci_2D( &
  a, a_c, nx_r, nx_c, ny )
!**********************************************************************
use types, only : rprec
implicit none

real(rprec) :: a(nx_r,ny), a_c(nx_c,ny) ! Device memory
integer, value :: nx_r, nx_c, ny

integer :: i, j, k, tx, ty, tz, ir, ii
!integer :: tx_r, tx_i
real(rprec) :: a_r, a_i, a_c_i

!real(rprec), shared :: a_sub(32,16,1)
!real(rprec), shared :: a_c_sub(16,16)

! Get the thread indices (with thread block)
tx = threadidx%x
ty = threadidx%y
!tz = threadidx%z

! Get the global index of complex array 
i = (blockidx%x-1) * blockdim%x + tx
j = (blockidx%y-1) * blockdim%y + ty
!k = (blockidx%z-1) * blockdim%z + tz

ii = 2*i
ir = ii - 1
!tx_i = 2*tx
!tx_r = tx_i - 1

!  Grab global data to shared arrays
!a_sub(tx_r:tx_i,ty,tz) = a(ir:ii,j,k)
!if(tz == 1) a_c_sub(tx,ty) = a_c(i,j)
!a_sub(tx_r:tx_i,ty,tz) = a(i,j,k)
! Wait until all elements are filled
!call syncthreads()

!if( k <= nz ) then
  if( j <= ny ) then
    if( i <= nx_c ) then

!      ii = 2*i
!      ir = ii - 1

      a_r = a(ir,j)
      a_i = a(ii,j)
      a_c_i = a_c(i,j)
      !a_c_i = a_c_sub(tx,ty)

      a(ir,j) = -a_i*a_c_i
      a(ii,j) = a_r*a_c_i

!      a(ir,j,k) = -a_i*a_c_sub(tx,ty)
!      a(ii,j,k) = a_r*a_c_sub(tx,ty)

!      a(ir,j,k) = -a_sub(tx_i,ty,tz)*a_c_sub(tx,ty)
!      a(ii,j,k) = a_sub(tx_r,ty,tz)*a_c_sub(tx,ty)  

    endif
  endif
!endif

!a(ir,j,k) = -a_sub(tx_i,ty,tz)*a_c_sub(tx,ty)
!a(ii,j,k) = a_sub(tx_r,ty,tz)*a_c_sub(tx,ty)

!call syncthreads()
!deallocate(a_r_loc, a_i_loc)

return

end subroutine cuda_emul_cmplx_mult_inpl_rci_2D

end module cuda_derivatives
